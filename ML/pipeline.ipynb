{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@SouthwestAir cool the plane you said is ours that just left the terminal for a diff city? She a cold betch for \"flying the friendly skies\"'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data\n",
    "path_data_train = \"/Users/jerome/Documents/level_up/ML/data/sentiment_train.csv\"\n",
    "train = pd.DataFrame.from_csv(path_data_train, encoding = \"ISO-8859-1\", index_col = None)\n",
    "path_data_test = \"/Users/jerome/Documents/level_up/ML/data/sentiment_test.csv\"\n",
    "test = pd.DataFrame.from_csv(path_data_test, encoding = \"ISO-8859-1\", index_col = None)\n",
    "train.iloc[1][\"tweet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_username_ flight _numeric_ in d fw now delay _numeric_ hour wait sit in plane for baggag to be load whi', '_username_ cool the plane you said is our that just left the termin for a diff citi she a cold betch for fli the friend sky', '_username_ well then that is a horribl flaw in your system _numeric_ hour in the past day i ve wast i ve got a job amp famili this is crazi', '_username_ thank i think we ve got it figur out', '_username_ don t want to clog your alreadi crowd line with a special meal request can someon dm me to sort out vegetarianproblem']\n",
      "(22633, 3632)\n",
      "(22633, 3632)\n"
     ]
    }
   ],
   "source": [
    "texts_train = train['tweet'].fillna(\"\").values\n",
    "labels_train = train['sentiment'].values\n",
    "\n",
    "texts_test = train['tweet'].fillna(\"\").values\n",
    "labels_test = train['sentiment'].values\n",
    "\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk import RegexpTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "def isNumeric(word):\n",
    "    try:\n",
    "        tmp = float(word)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "def preprocessing(word):\n",
    "    if isNumeric(word):\n",
    "        return \"_numeric_\"\n",
    "    elif re.search(\"^@\", word):\n",
    "        return \"_username_\"\n",
    "    else:\n",
    "        return stemmer.stem(word)\n",
    "\n",
    "tokenizer = RegexpTokenizer('@?\\w+', flags = re.UNICODE, gaps = False)\n",
    "\n",
    "new_texts_train = []\n",
    "for tweet in texts_train:\n",
    "    tweet = \" \".join([preprocessing(word) for word in tokenizer.tokenize(tweet)])\n",
    "    new_texts_train.append(tweet)\n",
    "print(new_texts_train[:5])\n",
    "\n",
    "new_texts_test = []\n",
    "for tweet in texts_train:\n",
    "    tweet = \" \".join([preprocessing(word) for word in tokenizer.tokenize(tweet)])\n",
    "    new_texts_test.append(tweet)   \n",
    "\n",
    "tfidf = TfidfVectorizer(min_df=5)\n",
    "\n",
    "X_train = tfidf.fit_transform(new_texts_train)\n",
    "print(X_train.shape)\n",
    "X_test = tfidf.transform(new_texts_test)\n",
    "print(X_test.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] ........................................... C=0.01, total=   0.2s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] ........................................... C=0.01, total=   0.1s\n",
      "[CV] C=0.01 ..........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........................................... C=0.01, total=   0.1s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ............................................ C=0.1, total=   0.2s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ............................................ C=0.1, total=   0.2s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ............................................ C=0.1, total=   0.2s\n",
      "[CV] C=1 .............................................................\n",
      "[CV] .............................................. C=1, total=   0.3s\n",
      "[CV] C=1 .............................................................\n",
      "[CV] .............................................. C=1, total=   0.3s\n",
      "[CV] C=1 .............................................................\n",
      "[CV] .............................................. C=1, total=   0.3s\n",
      "[CV] C=10 ............................................................\n",
      "[CV] ............................................. C=10, total=   0.5s\n",
      "[CV] C=10 ............................................................\n",
      "[CV] ............................................. C=10, total=   0.5s\n",
      "[CV] C=10 ............................................................\n",
      "[CV] ............................................. C=10, total=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    3.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1}\n",
      "0.749348296735\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.84      0.90      0.87      9324\n",
      "    neutral       0.75      0.82      0.78      8587\n",
      "   positive       0.80      0.56      0.66      4722\n",
      "\n",
      "avg / total       0.80      0.80      0.79     22633\n",
      "\n",
      "[[8363  774  187]\n",
      " [1097 7028  462]\n",
      " [ 521 1558 2643]]\n",
      "0.796801131092\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "logistic = LogisticRegression()\n",
    "kfold = KFold(n_splits=3, shuffle=True)\n",
    "\n",
    "parameters = {'C': [0.01, 0.1, 1, 10]}\n",
    "scoring = \"accuracy\"\n",
    "\n",
    "cross = GridSearchCV(logistic, parameters, \n",
    "                     scoring=scoring,\n",
    "                     cv=kfold, \n",
    "                     verbose=2\n",
    "                    )\n",
    "cross.fit(X_train, labels_train)\n",
    "print(cross.best_params_)\n",
    "print(cross.best_score_)\n",
    "\n",
    "y_pred = cross.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(classification_report(labels_test, y_pred))\n",
    "print(confusion_matrix(labels_test, y_pred))\n",
    "print(accuracy_score(labels_test, y_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "[CV] alpha=0 .........................................................\n",
      "[CV] .......................................... alpha=0, total=   0.1s\n",
      "[CV] alpha=0 .........................................................\n",
      "[CV] .......................................... alpha=0, total=   0.1s\n",
      "[CV] alpha=0 .........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......................................... alpha=0, total=   0.1s\n",
      "[CV] alpha=0.2 .......................................................\n",
      "[CV] ........................................ alpha=0.2, total=   0.1s\n",
      "[CV] alpha=0.2 .......................................................\n",
      "[CV] ........................................ alpha=0.2, total=   0.1s\n",
      "[CV] alpha=0.2 .......................................................\n",
      "[CV] ........................................ alpha=0.2, total=   0.1s\n",
      "[CV] alpha=0.4 .......................................................\n",
      "[CV] ........................................ alpha=0.4, total=   0.1s\n",
      "[CV] alpha=0.4 .......................................................\n",
      "[CV] ........................................ alpha=0.4, total=   0.1s\n",
      "[CV] alpha=0.4 .......................................................\n",
      "[CV] ........................................ alpha=0.4, total=   0.1s\n",
      "[CV] alpha=0.6 .......................................................\n",
      "[CV] ........................................ alpha=0.6, total=   0.1s\n",
      "[CV] alpha=0.6 .......................................................\n",
      "[CV] ........................................ alpha=0.6, total=   0.1s\n",
      "[CV] alpha=0.6 .......................................................\n",
      "[CV] ........................................ alpha=0.6, total=   0.1s\n",
      "[CV] alpha=0.8 .......................................................\n",
      "[CV] ........................................ alpha=0.8, total=   0.1s\n",
      "[CV] alpha=0.8 .......................................................\n",
      "[CV] ........................................ alpha=0.8, total=   0.1s\n",
      "[CV] alpha=0.8 .......................................................\n",
      "[CV] ........................................ alpha=0.8, total=   0.1s\n",
      "[CV] alpha=1 .........................................................\n",
      "[CV] .......................................... alpha=1, total=   0.1s\n",
      "[CV] alpha=1 .........................................................\n",
      "[CV] .......................................... alpha=1, total=   0.1s\n",
      "[CV] alpha=1 .........................................................\n",
      "[CV] .......................................... alpha=1, total=   0.1s\n",
      "{'alpha': 0.4}\n",
      "0.708788052843\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.75      0.90      0.82      9324\n",
      "    neutral       0.77      0.65      0.70      8587\n",
      "   positive       0.68      0.61      0.64      4722\n",
      "\n",
      "avg / total       0.74      0.74      0.74     22633\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:    1.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8420  634  270]\n",
      " [1958 5552 1077]\n",
      " [ 850 1000 2872]]\n",
      "0.744223037158\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "count = CountVectorizer(\n",
    "            min_df=5)\n",
    "\n",
    "X_train_count = count.fit_transform(new_texts_train)\n",
    "X_test_count = count.transform(new_texts_test)\n",
    "\n",
    "multinomial = MultinomialNB()\n",
    "\n",
    "parameters = {'alpha': [0, 0.2, 0.4, 0.6, 0.8, 1]}\n",
    "\n",
    "cross = GridSearchCV(multinomial, parameters, \n",
    "                     scoring=scoring,\n",
    "                     cv=kfold, \n",
    "                     verbose=2\n",
    "                    )\n",
    "\n",
    "cross.fit(X_train_count, labels_train)\n",
    "print(cross.best_params_)\n",
    "print(cross.best_score_)\n",
    "\n",
    "y_pred = cross.predict(X_test_count)\n",
    "\n",
    "print(classification_report(labels_test, y_pred))\n",
    "print(confusion_matrix(labels_test, y_pred))\n",
    "print(accuracy_score(labels_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n",
      "[CV] clf__C=0.1, vect__min_df=1, vect__ngram_range=(1, 1) ............\n",
      "[CV] clf__C=0.1, vect__min_df=1, vect__ngram_range=(1, 1) ............\n",
      "[CV] clf__C=0.1, vect__min_df=1, vect__ngram_range=(1, 1) ............\n",
      "[CV] clf__C=0.1, vect__min_df=1, vect__ngram_range=(1, 2) ............\n",
      "[CV]  clf__C=0.1, vect__min_df=1, vect__ngram_range=(1, 1), total=   1.6s\n",
      "[CV]  clf__C=0.1, vect__min_df=1, vect__ngram_range=(1, 1), total=   1.7s\n",
      "[CV] clf__C=0.1, vect__min_df=1, vect__ngram_range=(1, 2) ............\n",
      "[CV]  clf__C=0.1, vect__min_df=1, vect__ngram_range=(1, 1), total=   1.7s\n",
      "[CV] clf__C=0.1, vect__min_df=1, vect__ngram_range=(1, 2) ............\n",
      "[CV] clf__C=0.1, vect__min_df=5, vect__ngram_range=(1, 1) ............\n",
      "[CV]  clf__C=0.1, vect__min_df=5, vect__ngram_range=(1, 1), total=   1.4s\n",
      "[CV] clf__C=0.1, vect__min_df=5, vect__ngram_range=(1, 1) ............\n",
      "[CV]  clf__C=0.1, vect__min_df=1, vect__ngram_range=(1, 2), total=   4.1s\n",
      "[CV] clf__C=0.1, vect__min_df=5, vect__ngram_range=(1, 1) ............\n",
      "[CV]  clf__C=0.1, vect__min_df=5, vect__ngram_range=(1, 1), total=   1.5s\n",
      "[CV] clf__C=0.1, vect__min_df=5, vect__ngram_range=(1, 2) ............\n",
      "[CV]  clf__C=0.1, vect__min_df=5, vect__ngram_range=(1, 1), total=   1.4s\n",
      "[CV] clf__C=0.1, vect__min_df=5, vect__ngram_range=(1, 2) ............\n",
      "[CV]  clf__C=0.1, vect__min_df=1, vect__ngram_range=(1, 2), total=   4.2s\n",
      "[CV]  clf__C=0.1, vect__min_df=1, vect__ngram_range=(1, 2), total=   4.3s\n",
      "[CV] clf__C=0.1, vect__min_df=5, vect__ngram_range=(1, 2) ............\n",
      "[CV] clf__C=0.1, vect__min_df=10, vect__ngram_range=(1, 1) ...........\n",
      "[CV]  clf__C=0.1, vect__min_df=10, vect__ngram_range=(1, 1), total=   1.4s\n",
      "[CV] clf__C=0.1, vect__min_df=10, vect__ngram_range=(1, 1) ...........\n",
      "[CV]  clf__C=0.1, vect__min_df=5, vect__ngram_range=(1, 2), total=   3.5s\n",
      "[CV] clf__C=0.1, vect__min_df=10, vect__ngram_range=(1, 1) ...........\n",
      "[CV]  clf__C=0.1, vect__min_df=10, vect__ngram_range=(1, 1), total=   1.4s\n",
      "[CV] clf__C=0.1, vect__min_df=10, vect__ngram_range=(1, 2) ...........\n",
      "[CV]  clf__C=0.1, vect__min_df=5, vect__ngram_range=(1, 2), total=   3.6s\n",
      "[CV] clf__C=0.1, vect__min_df=10, vect__ngram_range=(1, 2) ...........\n",
      "[CV]  clf__C=0.1, vect__min_df=5, vect__ngram_range=(1, 2), total=   3.6s\n",
      "[CV] clf__C=0.1, vect__min_df=10, vect__ngram_range=(1, 2) ...........\n",
      "[CV]  clf__C=0.1, vect__min_df=10, vect__ngram_range=(1, 1), total=   1.4s\n",
      "[CV] clf__C=1, vect__min_df=1, vect__ngram_range=(1, 1) ..............\n",
      "[CV]  clf__C=1, vect__min_df=1, vect__ngram_range=(1, 1), total=   1.6s\n",
      "[CV] clf__C=1, vect__min_df=1, vect__ngram_range=(1, 1) ..............\n",
      "[CV]  clf__C=0.1, vect__min_df=10, vect__ngram_range=(1, 2), total=   3.6s\n",
      "[CV] clf__C=1, vect__min_df=1, vect__ngram_range=(1, 1) ..............\n",
      "[CV]  clf__C=0.1, vect__min_df=10, vect__ngram_range=(1, 2), total=   3.6s\n",
      "[CV] clf__C=1, vect__min_df=1, vect__ngram_range=(1, 2) ..............\n",
      "[CV]  clf__C=0.1, vect__min_df=10, vect__ngram_range=(1, 2), total=   3.4s\n",
      "[CV] clf__C=1, vect__min_df=1, vect__ngram_range=(1, 2) ..............\n",
      "[CV]  clf__C=1, vect__min_df=1, vect__ngram_range=(1, 1), total=   1.6s\n",
      "[CV] clf__C=1, vect__min_df=1, vect__ngram_range=(1, 2) ..............\n",
      "[CV]  clf__C=1, vect__min_df=1, vect__ngram_range=(1, 1), total=   1.7s\n",
      "[CV] clf__C=1, vect__min_df=5, vect__ngram_range=(1, 1) ..............\n",
      "[CV]  clf__C=1, vect__min_df=5, vect__ngram_range=(1, 1), total=   1.7s\n",
      "[CV] clf__C=1, vect__min_df=5, vect__ngram_range=(1, 1) ..............\n",
      "[CV]  clf__C=1, vect__min_df=5, vect__ngram_range=(1, 1), total=   2.5s\n",
      "[CV] clf__C=1, vect__min_df=5, vect__ngram_range=(1, 1) ..............\n",
      "[CV]  clf__C=1, vect__min_df=1, vect__ngram_range=(1, 2), total=   5.6s\n",
      "[CV] clf__C=1, vect__min_df=5, vect__ngram_range=(1, 2) ..............\n",
      "[CV]  clf__C=1, vect__min_df=1, vect__ngram_range=(1, 2), total=   6.0s\n",
      "[CV]  clf__C=1, vect__min_df=1, vect__ngram_range=(1, 2), total=   5.9s\n",
      "[CV] clf__C=1, vect__min_df=5, vect__ngram_range=(1, 2) ..............\n",
      "[CV] clf__C=1, vect__min_df=5, vect__ngram_range=(1, 2) ..............\n",
      "[CV]  clf__C=1, vect__min_df=5, vect__ngram_range=(1, 1), total=   1.8s\n",
      "[CV] clf__C=1, vect__min_df=10, vect__ngram_range=(1, 1) .............\n",
      "[CV]  clf__C=1, vect__min_df=10, vect__ngram_range=(1, 1), total=   1.9s\n",
      "[CV] clf__C=1, vect__min_df=10, vect__ngram_range=(1, 1) .............\n",
      "[CV]  clf__C=1, vect__min_df=5, vect__ngram_range=(1, 2), total=   4.8s\n",
      "[CV] clf__C=1, vect__min_df=10, vect__ngram_range=(1, 1) .............\n",
      "[CV]  clf__C=1, vect__min_df=5, vect__ngram_range=(1, 2), total=   4.7s\n",
      "[CV]  clf__C=1, vect__min_df=5, vect__ngram_range=(1, 2), total=   4.7s\n",
      "[CV] clf__C=1, vect__min_df=10, vect__ngram_range=(1, 2) .............\n",
      "[CV] clf__C=1, vect__min_df=10, vect__ngram_range=(1, 2) .............\n",
      "[CV]  clf__C=1, vect__min_df=10, vect__ngram_range=(1, 1), total=   1.8s\n",
      "[CV] clf__C=1, vect__min_df=10, vect__ngram_range=(1, 2) .............\n",
      "[CV]  clf__C=1, vect__min_df=10, vect__ngram_range=(1, 1), total=   1.8s\n",
      "[CV] clf__C=10, vect__min_df=1, vect__ngram_range=(1, 1) .............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   36.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__C=10, vect__min_df=1, vect__ngram_range=(1, 1), total=   2.5s\n",
      "[CV] clf__C=10, vect__min_df=1, vect__ngram_range=(1, 1) .............\n",
      "[CV]  clf__C=1, vect__min_df=10, vect__ngram_range=(1, 2), total=   4.4s\n",
      "[CV] clf__C=10, vect__min_df=1, vect__ngram_range=(1, 1) .............\n",
      "[CV]  clf__C=1, vect__min_df=10, vect__ngram_range=(1, 2), total=   4.4s\n",
      "[CV] clf__C=10, vect__min_df=1, vect__ngram_range=(1, 2) .............\n",
      "[CV]  clf__C=1, vect__min_df=10, vect__ngram_range=(1, 2), total=   4.5s\n",
      "[CV] clf__C=10, vect__min_df=1, vect__ngram_range=(1, 2) .............\n",
      "[CV]  clf__C=10, vect__min_df=1, vect__ngram_range=(1, 1), total=   3.3s\n",
      "[CV] clf__C=10, vect__min_df=1, vect__ngram_range=(1, 2) .............\n",
      "[CV]  clf__C=10, vect__min_df=1, vect__ngram_range=(1, 1), total=   2.9s\n",
      "[CV] clf__C=10, vect__min_df=5, vect__ngram_range=(1, 1) .............\n",
      "[CV]  clf__C=10, vect__min_df=5, vect__ngram_range=(1, 1), total=   2.6s\n",
      "[CV] clf__C=10, vect__min_df=5, vect__ngram_range=(1, 1) .............\n",
      "[CV]  clf__C=10, vect__min_df=1, vect__ngram_range=(1, 2), total=   8.7s\n",
      "[CV] clf__C=10, vect__min_df=5, vect__ngram_range=(1, 1) .............\n",
      "[CV]  clf__C=10, vect__min_df=5, vect__ngram_range=(1, 1), total=   3.0s\n",
      "[CV] clf__C=10, vect__min_df=5, vect__ngram_range=(1, 2) .............\n",
      "[CV]  clf__C=10, vect__min_df=1, vect__ngram_range=(1, 2), total=   9.5s\n",
      "[CV] clf__C=10, vect__min_df=5, vect__ngram_range=(1, 2) .............\n",
      "[CV]  clf__C=10, vect__min_df=1, vect__ngram_range=(1, 2), total=   9.0s\n",
      "[CV]  clf__C=10, vect__min_df=5, vect__ngram_range=(1, 1), total=   2.0s\n",
      "[CV] clf__C=10, vect__min_df=5, vect__ngram_range=(1, 2) .............\n",
      "[CV] clf__C=10, vect__min_df=10, vect__ngram_range=(1, 1) ............\n",
      "[CV]  clf__C=10, vect__min_df=10, vect__ngram_range=(1, 1), total=   2.0s\n",
      "[CV] clf__C=10, vect__min_df=10, vect__ngram_range=(1, 1) ............\n",
      "[CV]  clf__C=10, vect__min_df=5, vect__ngram_range=(1, 2), total=   4.8s\n",
      "[CV] clf__C=10, vect__min_df=10, vect__ngram_range=(1, 1) ............\n",
      "[CV]  clf__C=10, vect__min_df=5, vect__ngram_range=(1, 2), total=   4.9s\n",
      "[CV] clf__C=10, vect__min_df=10, vect__ngram_range=(1, 2) ............\n",
      "[CV]  clf__C=10, vect__min_df=10, vect__ngram_range=(1, 1), total=   1.9s\n",
      "[CV] clf__C=10, vect__min_df=10, vect__ngram_range=(1, 2) ............\n",
      "[CV]  clf__C=10, vect__min_df=5, vect__ngram_range=(1, 2), total=   4.7s\n",
      "[CV] clf__C=10, vect__min_df=10, vect__ngram_range=(1, 2) ............\n",
      "[CV]  clf__C=10, vect__min_df=10, vect__ngram_range=(1, 1), total=   2.1s\n",
      "[CV]  clf__C=10, vect__min_df=10, vect__ngram_range=(1, 2), total=   4.1s\n",
      "[CV]  clf__C=10, vect__min_df=10, vect__ngram_range=(1, 2), total=   4.1s\n",
      "[CV]  clf__C=10, vect__min_df=10, vect__ngram_range=(1, 2), total=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  54 out of  54 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__C': 10, 'vect__min_df': 1, 'vect__ngram_range': (1, 2)}\n",
      "0.763266027482\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.99      0.99      0.99      9324\n",
      "    neutral       0.96      0.99      0.97      8587\n",
      "   positive       0.98      0.94      0.96      4722\n",
      "\n",
      "avg / total       0.98      0.98      0.98     22633\n",
      "\n",
      "[[9189  126    9]\n",
      " [  48 8466   73]\n",
      " [   9  264 4449]]\n",
      "0.976627048999\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', LogisticRegression()),\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'vect__min_df': (1, 5, 10),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    'clf__C': (0.1, 1, 10)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=2, cv=kfold)\n",
    "grid_search.fit(new_texts_train,labels_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)\n",
    "\n",
    "y_pred = grid_search.predict(new_texts_test)\n",
    "\n",
    "print(classification_report(labels_test, y_pred))\n",
    "print(confusion_matrix(labels_test, y_pred))\n",
    "print(accuracy_score(labels_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
